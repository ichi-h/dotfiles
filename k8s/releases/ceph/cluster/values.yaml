cephClusterSpec:
  storage:
    useAllNodes: false
    useAllDevices: false
    # TODO: Write nodes
    # nodes:
    #   - name: "172.17.4.201"
    #     devices: # specific devices to use for storage can be specified for each node
    #       - name: "sdb"
    #       - name: "nvme01" # multiple osds can be created on high performance devices
    #         config:
    #           osdsPerDevice: "5"
    #       - name: "/dev/disk/by-id/ata-ST4000DM004-XXXX" # devices can be specified using full udev paths
    #     config: # configuration can be specified at the node level which overrides the cluster level config
    #   - name: "172.17.4.301"
    #     deviceFilter: "^sd."
  placement:
    all:
      nodeAffinity:
        required:
          nodeSelectorTerms:
            - matchExpressions:
                - key: role
                  operator: In
                  values:
                    - application

cephBlockPools:
cephObjectStores:
cephFileSystems:
  - name: myfs
    # see https://github.com/rook/rook/blob/master/Documentation/CRDs/Shared-Filesystem/ceph-filesystem-crd.md#filesystem-settings for available configuration
    spec:
      metadataPool:
        replicated:
          size: 1
      dataPools:
        - name: default
          replicated:
            size: 1
      metadataServer:
        activeCount: 1
        activeStandby: true
    storageClass:
      enabled: false
      isDefault: false
